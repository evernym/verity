######################################################
# Verity Application Reference Config File          #
######################################################

akka {
  loglevel = "INFO"
  stdout-loglevel = "INFO"
  # <K8S_SKIP>
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  # <K8S_SKIP>
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {

    # TODO: this 'java-serialization' is only turned 'on' to allow deserialization of
    # legacy/deprecated 'TransformedMultiEvents/TransformedEvent' (java serialized event)
    # once actor state cleanup (thread context migration etc) is done,
    # we can/should remove this config
    # <K8S_SKIP>
    allow-java-serialization = on

    debug {
      # enable function of Actor.loggable(), which is to log any received message
      # at DEBUG level, see the “Testing Actor Systems” section of the Akka
      # Documentation at http://akka.io/docs
      receive = on

      # enable DEBUG logging of subscription changes on the eventStream
      event-stream = off

      # enable DEBUG logging of unhandled messages
      unhandled = on

      # enable WARN logging of misconfigured routers
      router-misconfiguration = on

    }

    # <K8S_SKIP>
    serializers {
      protoser = "com.evernym.verity.actor.serializers.ProtoBufSerializer"
      kryo-akka = "com.twitter.chill.akka.AkkaSerializer"
    }

    # <K8S_SKIP>
    serialization-bindings {
      "com.evernym.verity.actor.DeprecatedEventMsg" = protoser
      "com.evernym.verity.actor.DeprecatedStateMsg" = protoser
      "com.evernym.verity.actor.DeprecatedMultiEventMsg" = protoser

      "com.evernym.verity.actor.PersistentMsg" = protoser
      "com.evernym.verity.actor.PersistentMultiEventMsg" = protoser

      "com.evernym.verity.actor.ActorMessage" = kryo-akka
    }

    # <K8S_SKIP>
    dispatchers {
      wallet-dispatcher {
        type = Dispatcher
        executor = "thread-pool-executor"
        thread-pool-executor {
          fixed-pool-size = 64
        }
        throughput = 1
      }
    }
    # <K8S_SKIP>
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  cluster {
    sharding {
      passivate-idle-entity-after = off
      updating-state-timeout = 25s
    }
    auto-down-unreachable-after = off
    unreachable-nodes-reaper-interval = 10s
  }

  discovery {
    kubernetes-api {
      pod-label-selector = "app=%s" # same as the default
    }
  }

  management {
    http {
      enabled = false
      port = 8558
    }

    cluster.bootstrap {
      enabled = false
      contact-point-discovery {
        service-name = "verity"
        discovery-method = kubernetes-api
      }
    }
  }

  http {
    client {
      parsing {
        max-content-length = 17m
      }
    }

    server {
      remote-address-header = on
      parsing {
        max-uri-length = 67k // 64k (for large invite URLs) + 2k buffer
        max-content-length = 17m
      }
    }

    parsing {
      illegal-header-warnings = off
    }

    host-connection-pool.max-open-requests = 256
  }

  persistence {
    journal {
      plugin = "akka.persistence.journal.leveldb"
    }
    snapshot-store {
      plugin = "akka.persistence.snapshot-store.local"
    }
  }

  remote {
    log-remote-lifecycle-events = off


    # Changing threshold to 12 as recommended in the docs. http://doc.akka.io/docs/akka/current/scala/remoting.html#Failure_Detector
    watch-failure-detector.threshold = 12.0

    artery {
      log-sent-messages = off
      canonical {
        # put IP address which other cluster member can reach to (REVIEW_AND_DECIDE)
        hostname = "<getHostAddress>"
      }
      advanced.maximum-frame-size = 4 MiB
    }


  }

  # this is used to know "Legacy" region actor names for "user-agent" and "user-agent-pairwise" actors
  sharding-region-name {
    user-agent = "VerityAgent"
    user-agent-pairwise = "VerityAgentPairwise"
  }

  extensions = [
    "com.evernym.verity.actor.node_singleton.ResourceWarningStatusMngrCache",
    "com.evernym.verity.actor.node_singleton.ResourceBlockingStatusMngrCache",
    "com.evernym.verity.actor.node_singleton.MsgProgressTrackerCache",
    "com.evernym.verity.actor.appStateManager.AppStateUpdateAPI"
  ]
}

verity {
  agent {
    authentication {

      # determines if this feature is by default available or not
      enabled: false

      # map of 'domain-id' and their authorized keys
      # <K8S_SKIP>
      keys {
        # provided keys will be available to agent belonging to given DID as key
        # examples:
        # domain-id-1: ["key1", "key2"]
        # domain-id-2: ["key3", "key4"]
      }
    }

    # <K8S-SKIP>
    actor-state-cleanup {

      # determines if actor state cleanup (fixing agent route and thread context migration)
      # is enabled or not
      # default value is false until we push a final change to make the whole flow working.
      enabled = true

      # there is a 'ActorStateCleanupManager' actor (as a child of cluster singleton actor)
      # which uses below 'manager' configuration to decide it's behaviour.
      manager {

        # how many parallel 'agent route store' actors will be asked for registeration
        registration {
          # (not hot-reloadable)
          batch-size = 20

          # this is to prevent hitting dynamodb too hard and impact the running service
	  # (not hot-reloadable)
          batch-item-sleep-interval-in-millis = 300
        }

        # how many max 'ActorStateCleanupExecutor' actor would be asked to start processing
        processor {
          # (not hot-reloadable)
          batch-size = 1

          # this is to prevent hitting dynamodb too hard and impact the running service
          # (not hot-reloadable)
          batch-item-sleep-interval-in-millis = 500
        }

        # scheduled job to orchestrating the processing
        scheduled-job {
          # (not hot-reloadable)
          interval-in-seconds = 120
        }
      }

      # there is a 'ActorStateCleanupExecutor' actor (sharded actor, per one 'agent route store' actor)
      # which uses below 'executor' configuration to decide it's behaviour.
      executor {
        # how many max 'routes/agent-actors' would be processed parallely
        # (not hot-reloadable)
        batch-size = 1

        # scheduled job to orchestrating the processing
        scheduled-job {
          # (not hot-reloadable)
          interval-in-seconds = 60
        }
      }
    }

    # <K8S-SKIP>
    migrate-thread-contexts {
      # (hot-reloadable)
      enabled = true

      # (not hot-reloadable)
      batch-size = 15
  
      # (not hot-reloadable)
      batch-item-sleep-interval-in-millis = 0

      scheduled-job {
        # (not hot-reloadable)
        interval-in-seconds = 120
      }
    }

    state.messages {
      get-msgs.limit = 920000

      # message retention/cleanup configuration
      cleanup {
        # if turned on, it will apply message retention logic
        # and accordingly remove messages from state in UserAgent and UserAgentPairwise actor
        # and if snapshot is enabled then in next snapshot those 'removed' messages won't be saved
        # and then next time when actor will recover from snapshot it will be without those 'removed' messages
        # (not hot reloadable for already spinnedup agent actors)
        enabled = true

        # how many days delivered messages should be retained in agent state
        # (not hot reloadable for already spinnedup agent actors)
        days-to-retain-delivered-msgs = 14

        # how many total messages to retain in agent state (non delivered will take priority in this list)
        # (not hot reloadable for already spinnedup agent actors)
        total-msgs-to-retain = 250
      }
    }

    endorser {
        # default endorser did
        did = ""
    }
  }

  app-state-manager {
    state {
      initializing {
        max-retry-count = 10
        max-retry-duration = 240
      }
      draining {
        delay-before-leave = 90
        delay-between-status-checks = 1
        max-status-check-count = 20
      }
    }
  }

  # General available blob storage
  blob-store {
    # The bucket name will contain <env> depending on which environment is used -> "verity-<env>-blob-storage"
    bucket-name = "blob-store"
    # Path to StorageAPI class to be used. Currently there is a LeveldbAPI and AlpakkaS3API
    storage-service = "com.evernym.verity.storage_services.leveldb.LeveldbAPI"
    # Optional field for the path to the local db store
    local-store-path = "/tmp/verity/leveldb"
  }

  alpakka.s3 {
    buffer = "memory"

    aws {
      credentials {
        provider = static
        access-key-id = ""
        secret-access-key = ""
      }

      region {
        provider = static
        default-region = "us-west-2"
      }
    }

    path-style-access = true
    endpoint-url = ""
}

  cache {
    key-value-mapper {
      expiration-time-in-seconds = 300
    }

    agent-config {
      expiration-time-in-seconds = 300
    }

    agency-detail {
      expiration-time-in-seconds = 1800
    }

    ledger-get-endpoint {
      expiration-time-in-seconds = 300
    }

    ledger-get-schema {
      expiration-time-in-seconds = 1800
    }

    ledger-get-cred-def {
      expiration-time-in-seconds = 1800
    }

    ledger-get-ver-key {
      expiration-time-in-seconds = 1800
    }

    routing-detail {
      expiration-time-in-seconds = 1800
    }

    wallet-get-ver-key {
      expiration-time-in-seconds = 1800
    }
  }

  config {

    # explict place to define paths to skip when generating the k8s helm template. This is
    # useful when in inline comment skip (<K8S_SKIP>) don't work. For example, resolved references
    # don't contain the origional comments to check.
    # <K8S_SKIP>
    k8s-skips = [
      "verity.dynamodb-journal.aws-access-key-id",
      "verity.dynamodb-journal.aws-secret-access-key",
      "verity.dynamodb-journal.endpoint",
      "verity.dynamodb-journal.journal-name",
      "verity.dynamodb-journal.tracing",
      "verity.dynamodb-snapshot-store.aws-access-key-id",
      "verity.dynamodb-snapshot-store.aws-secret-access-key",
      "verity.dynamodb-snapshot-store.endpoint",
      "verity.dynamodb-snapshot-store.journal-name",
      "verity.dynamodb-snapshot-store.tracing",
    ]

    # explict place to define paths that are not in the reference.conf but are should be configurable via
    # k8s helm template. Thses paths SHOULD NOT be in this file but will be added to the template.
    # <K8S_SKIP>
    k8s-includes = [
      "verity.salt.wallet-name",
      "verity.salt.wallet-encryption",
      "verity.salt.event-encryption",

      "verity.secret.routing-agent",
      "verity.secret.token-to-actor-item-mapper-actor",
      "verity.secret.url-mapper-actor",
      "verity.secret.key-value-mapper-actor",
      "verity.secret.user-warning-status-mngr",
      "verity.secret.user-blocking-status-mngr",
      "verity.secret.resource-usage-tracker",
    ]
  }

  dynamodb-common {
    # The service endpoint to connect to for the DynamoDB instance that
    # shall be used. Please refer to the AWS documentation for details.
    endpoint = ""
    aws-access-key-id = ""
    aws-secret-access-key = ""
    journal-name = ""

    # If this is set to `on` then every DynamoDB request will be logged
    # at DEBUG level. Caution: this will generate A LOT of output.
    tracing = off

    # AWS API limits - DO NOT CHANGE UNLESS YOU KNOW WHAT YOU ARE DOING
    # <K8S_SKIP>
    aws-api-limits {
      max-batch-get = 100
      max-batch-write = 25
      max-item-size = 400000
    }

    # AWS client configuration settings, see
    # http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/?com/amazonaws/ClientConfiguration.html
    #
    # (setting any of these to the string "default" means that the corresponding
    # setter method on the ClientConfiguration will not be invoked)
    # <K8S_SKIP>
    aws-client-config {
      client-execution-timeout = default     # int
      connection-max-idle-millis = default   # long
      connection-timeout = default           # int
      connection-ttl = default               # long
      local-address = default                # InetAddress
      max-connections = default              # int
      max-error-retry = default              # int
      preemptive-basic-proxy-auth = default  # boolean
      protocol = HTTPS            # HTTP or HTTPS
      proxy-domain = default                 # string
      proxy-host = default                   # string
      proxy-password = default               # string
      proxy-port = default                   # int
      proxy-username = default               # string
      proxy-workstation = default            # string
      request-timeout = default              # int
      response-metadata-cache-size = default # int
      signer-override = default              # string
      socket-buffer-size-hints = default     # [ int, int ] (for send & receive)
      socket-timeout = default               # int
      use-expect-continue = default          # boolean
      use-gzip = default                     # boolean
      use-reaper = default                   # boolean
      use-tcp-keepalive = default            # boolean
      user-agent = default                   # string
    }
    # <K8S_SKIP>
    dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
      }
    }
  }

  dynamodb-journal {
    # The logical journal name, used in the partition keys.
    journal-table = ""

    # The service endpoint to connect to for the DynamoDB instance that devin
    # shall be used. Please refer to the AWS documentation for details.
    # <K8S_SKIP>
    endpoint = ${verity.dynamodb-common.endpoint}

    # The logical journal name, used in the partition keys.
    # <K8S_SKIP>
    journal-name = ${verity.dynamodb-common.journal-name}

    # The AWS key ID to use for connecting to the specified endpoint.
    # <K8S_SKIP>
    aws-access-key-id = ${verity.dynamodb-common.aws-access-key-id}

    # The AWS secret to use in conjuction with the AWS key ID.
    # <K8S_SKIP>
    aws-secret-access-key = ${verity.dynamodb-common.aws-secret-access-key}

    # <K8S_SKIP>
    aws-client-config = ${verity.dynamodb-common.aws-client-config}

    # AWS API limits - DO NOT CHANGE UNLESS YOU KNOW WHAT YOU ARE DOING
    # <K8S_SKIP>
    aws-api-limits = ${verity.dynamodb-common.aws-api-limits}

    # If this is set to `on` then every DynamoDB request will be logged
    # at DEBUG level. Caution: this will generate A LOT of output.
    # <K8S_SKIP>
    tracing = ${verity.dynamodb-common.tracing}

    # The FQCN for the journal plugin implementation - DO NOT CHANGE
    # <K8S_SKIP>
    class = "akka.persistence.dynamodb.journal.DynamoDBJournal"

    # The dispatcher that executes the replay logic for this plugin
    # instance - should not normally need to be changed.
    # <K8S_SKIP>
    replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"

    # The dispatcher that executes the write logic for this plugin
    # instance - should not normally need to be changed.
    # <K8S_SKIP>
    plugin-dispatcher = "dynamodb-journal.dispatcher"

    # The number of shards to distribute the sequence number items over.
    sequence-shards = 10

    # number of concurrently running replay prefetch operations for a
    # single PersistentActor; this prefetch means that during a replay
    # more events might be retrieved than specified with the `max`
    # parameter, with corresponding usage DynamoDB read units
    replay-parallelism = 10

    # Set to `on` to log the detected configuration at INFO level at plugin startup.
    log-config = off

    # The dispatcher that executes the future combinators needed for
    # transforming the AmazonDynamoDBAsyncClient results (i.e.
    # handling the back-off etc.)
    # <K8S_SKIP>
    client-dispatcher = "dynamodb-journal.dispatcher"
  }

  dynamodb-snapshot-store {
    # <K8S_SKIP>
    class="akka.persistence.dynamodb.snapshot.DynamoDBSnapshotStore"
    # <K8S_SKIP>
    endpoint = ${verity.dynamodb-common.endpoint}
    # <K8S_SKIP>
    client-dispatcher = "dynamodb-journal.dispatcher"
    snapshot-table = ""
    # <K8S_SKIP>
    journal-name = ${verity.dynamodb-common.journal-name}
    # <K8S_SKIP>
    aws-access-key-id = ${verity.dynamodb-common.aws-access-key-id}
    # <K8S_SKIP>
    aws-secret-access-key = ${verity.dynamodb-common.aws-secret-access-key}

    # If this is set to `on` then every DynamoDB request will be logged
    # at DEBUG level. Caution: this will generate A LOT of output.
    tracing = ${verity.dynamodb-common.tracing}

    # <K8S_SKIP>
    aws-client-config =${verity.dynamodb-common.aws-client-config}

    # AWS API limits - DO NOT CHANGE UNLESS YOU KNOW WHAT YOU ARE DOING
    # <K8S_SKIP>
    aws-api-limits = ${verity.dynamodb-common.aws-api-limits}
  }

  endpoint = {
    # verity host
    host = "localhost"
    # verity default port
    port = "80"
    # agent msg rest api url path, keep default value
    # <K8S-SKIP>
    path-prefix = "agency/msg"
  }

  http {
    # the interface to listen on, keep it default unless you have specific requirement to change it
    interface = "0.0.0.0"

    # the port to listen on for http requests, change as per environment/need
    port = 9000

    # the port to listen on for https requests, change as per environment/need
    # you can comment it if you DON'T want to start ssl binding on this server
    # ssl-port = 9443
  }

  internal-api {
    # The verity setup and health related rest api resources (mostly starting with /agency/internal/... etc)
    # will only be callable from the list of "allowed-from-ip-addresses" (CIDR notation) below.
    # Note that one of the health related api resources shows configuration details, which may contain
    # sensitive information.
    #
    # If allowed-from-ip-addresses is undefined or an empty, by default all "site local" (10 dot, 127 dot,
    # and 172 dot addresses) and loopback intefaces (usually 127.0.0.1) will be allowed. If you add even one
    # CIDR address to the list, you must enumerate all addresses. In other words, if you add 1.2.3.4/32 to the
    # list and you also want all site local and loopback addresses to be allowed, you will need to add the
    # site local and loopback CIDR addresses to the list. The defaults are NOT included if the list is not
    # empty.
    # <K8S-SKIP>
    allowed-from-ip-addresses = ["127.0.0.1/32"]

    # this configuration controls if the 'persistent data' internal api
    # (http://<host>/agency/internal/maintenance/persistent-actor/<actor-type-name>/<actor-entity-id>/data)
    # example: /agency/internal/maintenance/persistent-actor/AgencyAgent/12345/data
    # is available or not for use.
    # the default value is 'false' due to security consideration
    # when it is 'true', then, anyone who has access to internal api (non root users)
    # can see persistent data (snapshot and events) of given persistent actor (bypassing data at rest security)
    persistent-data.enabled = false
  }

  item-manager {
    watcher {   # entity id of item manager actor
      version = "v2"
    }
  }

  item-container {

    mapper.class = "com.evernym.verity.actor.itemmanager.TimeBasedItemContainerMapper"

    scheduled-job {
      interval-in-seconds = 300
    }

    migration {
      chunk-size = 20
      check-result-history-size = 20
    }

  }

  # Unmaintained config. Used for https
  #keystore {
  #  # if you are running ssl-binding, then, provide path (relative to classpath) of .keystore file
  #  location = ".keystore"
  #
  #  # keystore file password
  #  password = "some-password"
  #  password = ${?KEYSTORE_PASSWORD}  //environment variable if set, override above value
  #}

  lib-indy {
    # library dir location which contains files like libindy.so, libmysqlstorage.so etc
    library-dir-location = "/usr/lib"

    flavor = async

    ledger {
      # defines where to fine the pool ledger genesis file. This file is used to bootstrap the pool ledger.
      genesis-txn-file-location = "/var/lib/indy/genesis.txt"

      # it helps libindy keeping different pool configurations in different directory
      # whatever name you provide here, a directory with that name gets created under ~/.indy_client/pool/
      # keeping default should also be ok
      pool-name = "default_pool"

      # defines which indy node txn protocol version to be used
      txn-protocol-version = 2

      transaction_author_agreement = {
        # Transaction Author Agreement
        # https://github.com/hyperledger/indy-sdk/blob/master/docs/how-tos/transaction-author-agreement.md
        #
        # When a Domain Ledger has a Transaction Author Agreement (TAA), configure the current version and any known future
        # versions of the TAA in the transaction_author_agreement configuration below. Each entry must be keyed off of the TAA
        # version and must contain:
        #
        #  - 'digest'
        #     A sha256 hash of the "<version><agreement text>" after trimming <version> and  <agreement text> of all leading and
        #     trailing whitespace. For example, sha256(1.0example TAA text) produces:
        #
        #     f8f50b0c2b7cef2d738cdc87a61fc95e789c80b8cfcb925df7367560500964d7
        #
        #  - 'mechanism'
        #    Verity should use 'on_file', but is configurable here in case the policy changes
        #
        #  - 'time-of-acceptance'
        #    Time of acceptance in yyyy-MM-dd format. You must predate future versions of the TAA with a
        #    time-of-acceptance that is on or after the announced go-live day for a future version. The Sovrin Foundation
        #    has proposed 24 hours before or after the go-live day. This will be configurable by the Sovrin Foundation.
        #    Whatever the Sovrin Foundation decides, it will be plus or minus the "TAA acceptance time valid deviations
        #    (secs)" as defined in indy-plenum:
        #    https://github.com/hyperledger/indy-plenum/blob/aae307ab6ea2c1b0dba4282736d5cfcf5accd28e/plenum/config.py#L410-L411
        #
        # There are several ways to get the current TAA version and text:
        #
        # Option 1: Attempt to bootstrap the verity and let it fail. The response JSON will contain the data you need to add
        # in transaction_author_agreement below. TODO: add verity URL used to bootstrap the Verity here
        #
        # Option 2: Use Indy CLI to get/review the version and text for the active TAA on the ledger
        # https://github.com/hyperledger/indy-sdk/blob/master/docs/how-tos/transaction-author-agreement.md#taa-acceptance-workflow
        # 1. Create and/or open a wallet
        # 2. Create and/or connect to the pool ledger. The TAA will be displayed during this process. Running `pool show-taa`
        #    after connecting to the pool is also an option.
        #
        # Option 3: Use indy-sdk API
        # https://github.com/hyperledger/indy-sdk/blob/master/docs/how-tos/transaction-author-agreement.md#user-get-aml-and-taa-set-on-the-ledger
        #
        # Example configuration version a version '1.0.0' with text 'TAA for agency-devlab ledger' would produce a
        # sha256(1.0.0TAA for agency-devlab ledger) hash of 3ae97ea501bd26b81c8c63da2c99696608517d6df8599210c7edaa7e2c719d65
        #
        # It is important to note that time-of-acceptance must be a date plus or minus the
        # "TAA acceptance time valid deviations (secs)" as defined in indy-plenum:
        # https://github.com/hyperledger/indy-plenum/blob/aae307ab6ea2c1b0dba4282736d5cfcf5accd28e/plenum/config.py#L410-L411
        #
        # agreements {
        #   "1.0" {
        #     "digest" = "3ae97ea501bd26b81c8c63da2c99696608517d6df8599210c7edaa7e2c719d65"
        #     "mechanism" = "on_file"
        #     "time-of-acceptance" = "2019-11-18"
        #   }
        # }
        # <K8S-SKIP>
        agreements = {}

        #
        # This setting will cause the following to happen:
        # 1. Will get taa(text and version) from ledger on connection.
        # 2. Will require a matching agreement for the version on the ledger
        # 3. Check that digest is correct for the version
        #
        enabled = false
      }

      pool-config {
        # Defines the timeout to open a pool connection with the ledger AND perform any necessary initialization
        # (i.e. detect and handle the Transaction Author Agreement) of  the Indy Ledger pool connection manager instance
        # in Verity. This should be at least extended-timeout (see below) seconds, but will not be enforced, and will
        # default to 60 seconds if not defined.
        connection-manager-open-timeout = 80

        # Defines the pool timeout in seconds
        # See POOL_ACK_TIMEOUT in indy-sdk/libindy/src/domain/pool.rs
        # See indy-sdk/libindy/src/services/pool/pool.rs:
        #   Call to _get_request_handler_with_ledger_status_sent while in PoolState::Initialization state with a PoolEvent::CheckCache event
        #   Call to _get_f while in PoolState::GettingCatchupTarget state with a PoolEvent::CatchupTargetFound event
        #   Call to _get_request_handler_with_ledger_status_sent while in PoolState::Active state with a PoolEvent::Refresh event
        #   Call to _get_f while in PoolState::Active state with a PoolEvent::SendRequest event
        #   possibly more...
        timeout = 20

        # Defines how long (in seconds) to extend a pool connection's timeout after receiving an ACK (reply) from events
        # processed by the connection. If no reply/ack is received in <extended-timeout> seconds, the pool connection is
        # closed/destroyed.
        # See POOL_REPLY_TIMEOUT in indy-sdk/libindy/src/domain/pool.rs
        # See indy-sdk/libindy/src/services/pool/networker.rs
        extended-timeout = 60

        # Defines the max requests serviced by a pool connection before creating a new pool connection (growing the pool)
        # Pool connections handle <conn-limit> requests before the pool connection is destroyed. In other words, pool
        # connections are rolling (consumed) rather than pooling (reused).
        # See MAX_REQ_PER_POOL_CON in indy-sdk/libindy/src/domain/pool.rs
        conn-limit = 5

        # Defines how long ZMQ polls for events on multiple sockets
        # See POOL_CON_ACTIVE_TO in indy-sdk/libindy/src/domain/pool.rs
        # ZMQ poll timeout. How long should the pool connection poll for events - See
        # indy-sdk/libindy/src/services/pool/pool.rs
        conn-active-timeout = 5
      }
    }

    wallet {
      type = "default"
    }
  }
  # <K8S-SKIP>
  logging.ignore-logger-filter.logger-name-contains = [
    "DynamoDBClient",
    "DynamoDBJournal",
    "FileUtil",
    "LinuxOperatingSystem",
    "LinuxDisks",
    "LinuxFileSystem"
    "Timer"
  ]

  maintenance {
    agent-routes-migrator {

      enabled = false    //TODO: to be decided if enabling it right away is fine?

      scheduled-job {
        interval-in-seconds = 10
      }

      registration {
        batch-size = 2    //how many parallel "legacy agent route store actor" to ask for registration
      }

      processing {
        batch-size = 2    //how many parallel "legacy agent route store actor" to be processed for migration
      }

      routes {
        //NOTE: whatever this batch size would be, that many entry will be stored by legacy agent route store
        // actor in one event, so make sure this batch-size is not so high that it exceeds
        // 400 k limit of dynamodb
        batch-size = 50    //how many parallel routes "per legacy agent route actor" to be migrated
        batch-item-interval-in-millis = 0   //gap between migrating each route
      }

    }
  }

  metrics {
    enabled = Y

    # the rules for filter execution are simple: any string is accepted by the filter if
    # it matches at least one of the includes patterns and doesn’t match any of the excludes patterns
    util {
      # <K8S-SKIP>
      filters {
        general {
          includes = [
            {"name": "akka_system_*"},
            {"name": "akka_group_*"},
            {"name": "akka_remote_*"},
            {"name": "executor_*"},
            {"name": "libindy_*"},
            {"name": "as*"},
            {"name": "jvm*"},
            {"name": "span*"}
          ]
          excludes = []
        }
      }
    }

    # There is a specific metric used for the start of protocols. 'uses-sponsor' and 'uses-sponsee' are optional tags
    # that specify if the metric should be tagged with the 'sponsorId' and/or the 'sponseeId'.
    # Typically
    #   - vas will have 'uses-sponsee'=true
    #   - cas will have 'uses-sponsor'=true
    protocol {
      tags {
        uses-sponsor = false
        uses-sponsee = false
      }
    }

    # <K8S-SKIP>
    activity-tracking {
      active-user {
        # Type=Duration -> Found at https://www.scala-lang.org/api/2.9.3/scala/concurrent/duration/Duration.html
        # This is a sliding window (+- timestamp) where the token is considered valid by Verity.
        # If expiration happens, requester will need to request a new token from their sponsor
        # Valid Units: `d, day, h, hour, min, minute, s, sec, second, ms, milli, millisecond, Âµs, micro, microsecond, ns, nano, nanosecond`
        # and their pluralized forms (for every but the first mentioned form of each unit, i.e. no "ds", but "days").
        time-windows = []
        # Monthly is not of type Duration so it can't go in the time-windows array. Monthly is handled a little differently in the code
        monthly-window = false
        enabled = false
      }

      active-relationships {
        # Type=Duration -> Found at https://www.scala-lang.org/api/2.9.3/scala/concurrent/duration/Duration.html
        # This is a sliding window (+- timestamp) where the token is considered valid by Verity.
        # If expiration happens, requester will need to request a new token from their sponsor
        # Valid Units: `d, day, h, hour, min, minute, s, sec, second, ms, milli, millisecond, Âµs, micro, microsecond, ns, nano, nanosecond`
        # and their pluralized forms (for every but the first mentioned form of each unit, i.e. no "ds", but "days").
        time-windows = []
        # Monthly is not of type Duration so it can't go in the time-windows array. Monthly is handled a little differently in the code
        monthly-window = false
        enabled = false
      }
    }

    latency-recording {
      histogram { enabled: false }
      span      { enabled: true }
    }
  }

  # Configure max size of incoming messages per message family
  # Size validation is not performed if message family is not specified in config
  # Default implementation checks for the following optional limits:
  # packed-msg-limit: Message limit for packed msg endpoint
  # rest-limit: Message limit for REST endpoint
  messages.limits {
      issue-credential {
          packed-msg-limit = 350000
          rest-limit = 350000
      }

      committedanswer {
          packed-msg-limit = 170000
          rest-limit = 170000
      }

      present-proof {
        packed-msg-limit = 293600
        rest-limit = 293600
      }
  }

  msg-template {
    # this is invitation url returned to invitation sender to be used for later purposes
    # this url is also being used by app to fetch invitation detail and show to invitee
    sms-msg-template-invite-url = "#{baseUrl}/agency/invite?t=#{token}"

    # this template is used to build sms content which we want to send to invitee
    sms-msg-template-offer-conn-msg = "#{requesterName} would like you to install Connect-Me for greater identity verification: #{appUrlLink}"

    # template by which deeplink urls are built
    sms-offer-template-deeplink-url = "https://connectme.app.link?t=#{token}"

    # <K8S-SKIP>
    agent-specific {
      # provided specific overrides for agents specified by given domainDID

      # example:
      # <domain-id-1>: {
      #   sms-msg-template-offer-conn-msg = "#{requesterName} would like to connect with you. #{appUrlLink}"
      #   sms-offer-template-deeplink-url = "https://masterpass.app.link?t=#{token}"
      # }
    }

  }

  msgs {
    # default value for connection request expiration time in seconds
    # specific enterprise agent then can update its own agent configuration to override this
    conn-req-expiration-time-in-seconds = 300
  }

  non-persistent-actor {
    base {
      # TODO this does not seem to be used?
      passivate-time-in-seconds = 600

      WalletActor {
        passivate-time-in-seconds = 600
      }
    }
  }

  out-of-band {
    service-key-did-format = false
  }

  persistence {

    # This config is used during storing transformed snapshot (protobified, encrypted etc)
    # to determine if it (post transformation) is not exceeding maximum allowed size.
    # For dynamodb tables with local secondary index, the max allowed size (400KB) includes
    # item data in main table + projected attributes defined in local secondary index
    # (see more details: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html#limits-items)
    # that is the reason the max snapshot size would/should be little less than half
    # (to be on safer side) of what dynamodb max size (400KB) is allowed in general.
    snapshot.max-item-size-in-bytes = 190000

    use-async-for-msg-forward-feature: false
  }

  # this section covers configuration for any persistent actors
  # it might be based on actor categories, entity type/name or entity id.
  persistent-actor {
    warn-recovery-time-milliseconds = 1000

    base {                                     # for base persistent actor category

      # if set to true, persistent actor will use last saved snapshot (if any) during recovery
      # if set to false, persistent actor will ignore any snapshot (if any) during recovery
      recover-from-snapshots = true

      # receive-timeout-seconds = 600          # applicable to all base persistent actor unless overridden specifically

      # example template
      # ActorType {                            # Replace 'ActorType' accordingly (like AgencyAgent, UserAgent etc)
      #   receive-timeout-seconds = 800        # applicable to all entity of type "ActorType" unless overridden specifically
      #   entity-id-1 {                        # application to only "ActorType-entity-id-1" actor
      #     receive-timeout-seconds = 1000
      #   }
      # }

      # TODO: make sure we are ok with corresponding 'state' proto buf message strucutre
      # before enabling the snapshot
      # TODO: finalize and enable configurations in this below section
      # before enabling/uncommenting them
      AgencyAgent {
        snapshot {
          after-n-events = 100
          keep-n-snapshots = 2
          delete-events-on-snapshots = true
        }
        supervisor {
          enabled = true
          strategy = OnFailure
          min-seconds = 1
          max-seconds = 360
          random-factor = 0.2
          max-nr-of-retries = 10
        }
      }
      AgencyAgentPairwise {
        snapshot {
          after-n-events = 100
          keep-n-snapshots = 2
          delete-events-on-snapshots = true
        }
        supervisor {
          enabled = true
          strategy = OnFailure
          min-seconds = 1
          max-seconds = 360
          random-factor = 0.2
          max-nr-of-retries = 10
        }
      }
      UserAgent {
        snapshot {
          after-n-events = 100
          keep-n-snapshots = 2
          delete-events-on-snapshots = true
        }
        supervisor {
          enabled = true
          strategy = OnFailure
          min-seconds = 1
          max-seconds = 360
          random-factor = 0.2
          max-nr-of-retries = 10
        }
      }
      UserAgentPairwise {
        snapshot {
          after-n-events = 100
          keep-n-snapshots = 2
          delete-events-on-snapshots = true
        }
        supervisor {
          enabled = true
          strategy = OnFailure
          min-seconds = 1
          max-seconds = 360
          random-factor = 0.2
          max-nr-of-retries = 10
        }
      }
    }

    # protocol-container {                     # applicable to all protocol container actors
    # similar structure as shown under 'base' category above
    # }

    # singleton-children {                     # for singleton children actor category
    # similar structure as shown under 'base' category above
    # }
  }

  # This is used to identify anyone who provisions
  provisioning {
    # sponsors:
    # name: The name of the Sponsor who endorses the provisioning .
    # id: An ID which will not change. Keys cannot be used because of rotation possibilities.
    # keys: VerKey used to sign the token. This can be expanded in the future.
    # endpoint: Endpoint where HTTP message will be sent. Sponsor's backend can deliver to the app however they want.
    # active: boolean if sponsor has an active status with Evernym
    # <K8S-SKIP>
    sponsors = []
    # Boolean -> some use cases will not what to deal with tokens such as veritysdk.
    sponsor-required = false
    # Type=Duration -> Found at https://www.scala-lang.org/api/2.9.3/scala/concurrent/duration/Duration.html
    # This is a sliding window (+- timestamp) where the token is considered valid by Verity.
    # If expiration happens, requester will need to request a new token from their sponsor
    # Valid Units: `d, day, h, hour, min, minute, s, sec, second, ms, milli, millisecond, Âµs, micro, microsecond, ns, nano, nanosecond`
    # and their pluralized forms (for every but the first mentioned form of each unit, i.e. no "ds", but "days").
    token-window = 10 minute
  }

  # <date time>
  #  - days up to 2 years  -> 1-730 days
  #  TODO: +Inf, and 0 which means on completion of the protocol
  retention-policy {
    # A retention policy can be set for a specific domain-id. If nothing is provided, the 'default' values will be used.
    # <protoref>: basicmessage, relationship, issue-credential, present-proof, questionanswer, wallet-backup

    # A retention policy can be set as a default for the entire environment.
    # This is overriden if a specific 'domain-id' provides configuration.
    default {
      # For all undefined protorefs, this is the default policy

      undefined-fallback {

        # defines after how many days data will be expired
        expire-after-days = 360 day

        # if set to true, irrespective of 'expire-after-days', data will be deleted
        # once protocol reaches to terminal state
        # if not set, by default it will be considered false
        expire-after-terminal-state = false
      }
      # you can also define default values for specific protocols
      # <protoref> {
      #   expire-after-days = <days>
      #   expire-after-terminal-state = <boolean>
      # }
    }

    #Example domain registry:
    # <domain-id> {
    #   <protoref> {
    #     expire-after-days = <days>
    #     expire-after-terminal-state = <boolean>
    #   }
    #   For all undefined protorefs, this is the default policy
    #   undefined-fallback {
    #     expire-after-days = <days>
    #     expire-after-terminal-state = <boolean>
    #   }
    # }
  }

  rest-api {
    # This enables the REST endpoint ('<server>/api')
    # If this is set to false, http will respond with 501 Not Implemented
    enabled = false
  }

  services {
    push-notif-service = {
      enabled = false
      general-msg-title-template = "Hi #{targetName}"
      general-new-msg-body-template = "#{senderName} sent you #{msgType}"
      error-resp-msg-body-template = "#{senderName} responded with error (detail: uid -> #{uid}, msg type -> #{msgType})"
      token-transfer-offer-new-msg-body-template = "#{senderName} wants to send you Sovrin tokens"
      token-transfer-req-new-msg-body-template = "#{senderName} is requesting Sovrin tokens"
      token-transferred-new-msg-body-template = "#{senderName} sent you Sovrin tokens"
      default-sender-name = "Remote connection"
      # <K8S-SKIP>
      msg-types-for-alert-push-notif = [
        "credOffer",
        "cred",
        "proofReq",
        "Question",
        "issue-credential/1.0/offer-credential",
        "issue-credential/1.0/issue-credential",
        "present-proof/1.0/request-presentation",
        "committedanswer/1.0/question",
        "questionanswer/1.0/question",
        "unknown"
      ]
      default-logo-url = ""

      fcm {
        host = "fcm.googleapis.com"
        path = "/fcm/send"
        key = ""
      }
    }

    sms-service {

      external-services {
        preferred-order = []
        open-market {
          user-name = ""
          password = ""
          service-id = ""
          endpoint {
            host = "servicemanager.openmarket.com"
            port = "443"
            path-prefix = "service/v1/invokeService"
          }
        }
      }
    }

    url-mapper-service {
      msg-template {
        # template by which shortened url is build
        connect-me-mapped-url-template = "https://connectme.app.link/?t=#{token}"
      }
      endpoint {
        host = ""
        port = 80
        path-prefix = "agency/url-mapper"
      }
    }

    url-shortener-service = {
      # Path to URLShortenerAPI class to be used (YOURLSSvc is available if configured)
      selected = ""
      yourls {
        api-url = ""
        signature = ""
        timeout-seconds = 10
      }
    }
  }

  # thread pool configurations
  thread-pools {
    # <K8S-SKIP>
    default-future {
      # if enabled, for all future code, it will use a custom thread pool executor with below mentioned size
      # if disabled, it will use scala provided implicit global execution context
      # size = 2000
    }

    wallet-future {
      # if enabled, for all wallet future code, it will use a custom thread pool executor with below mentioned size
      # if disabled, it will use above 'default-future' execution cotext configuration
      size = 64
    }
  }

  timeout {
    general-actor-ask-timeout-in-seconds = 30
    general-actor-ref-resolve-timeout-in-seconds = 15
  }

  url-mapper-api {
    enabled = false
  }

  user-agent-pairwise-actor {
    scheduled-job {
      interval-in-seconds = 300
    }
  }

  resource-usage-rules {
    usage-rules {
      default = {}
    }
    blacklisted-tokens = []
    whitelisted-tokens = []
  }

  wallet-storage {
    # the maximum number of database connections allowed
    connection-limit = 20
    read-host-ip = ""
    write-host-ip = ""
    host-port = "3306"
    credentials-username = ""
    credentials-password = ""
    db-name = "wallet"
  }
}

kamon {
  environment {
    host = ${verity.endpoint.host}
    service = "verity-application"
    tag {
      env = "ephemeral"
      version = ${?verity.version}
    }
  }

  # interval at which metric snapshots will be collected.
  metric.tick-interval = 15 second

  modules.jaeger.enabled = false
  modules.status-page.enabled = false

  #disable publishing the Prometheus scraping enpoint using a embedded server.
  # <K8S-SKIP>
  prometheus.start-embedded-http-server = no
  #disables default prometheus-reporter since we register our own custom reporters
  modules.prometheus-reporter.enabled = false

  modules.datadog-agent.enabled = false
  modules.datadog-trace-agent.enabled = false

  akka.ask-pattern-timeout-warning = lightweight

  # filters are used by several Kamon modules to determine whether to include or exclude
  # certain application components from metrics collection and tracing

  # the rules for filter execution are simple: any string is accepted by the filter if
  # it matches at least one of the includes patterns and doesn't match any of the excludes patterns
  # <K8S-SKIP>
  instrumentation {
    akka.filters {

      actors.track {
        includes = []
        excludes = []
      }

      dispatchers {
        includes = ["akka.actor.default-dispatcher"]
        excludes = []
      }

      trace {
        includes = ["**"]
        excludes = []
      }
    }

    logback.mdc {
      # this is needed for datadog to be able to track operation
      span-operation-name-key = "operation"
    }
  }

  # Disable features of kamon-system-metrics module that are enabled by default that we do not want
  # <K8S-SKIP>
  system-metrics {
    # The sigar library is enabled by default. Disable it due to a core dump while loading/using the sigar library.
    # A fatal error has been detected by the Java Runtime Environment:
    #
    #  SIGSEGV (0xb) at pc=0x00007fa04cf4d311, pid=12147, tid=0x00007fa04d146700
    #
    sigar-enabled = false

    host {
      # Disable collecting all host-level metrics in hopes that the sigar library won't be loaded/used and cause the
      # aforementioned (above) SIGSEGV (core dump)
      enabled = no
    }
  }
}

kanela {
  # <K8S-SKIP>
  show-banner = false
}

######################################################
# [END] Verity Applicationd Reference Config File    #
######################################################
